{
 "cells": [
  {
   "cell_type": "markdown", 
   "metadata": {
    "colab_type": "text",
    "id": "Bpviywt3lRAf"
   },
   "source": [
    "# Homework 4\n",
    "This homework will guide you step by step to train a CharRNN. \n",
    "This homework will show you how to use pytorch for building the pipline of deep learning task, including  \n",
    "\n",
    "* Loading data\n",
    "* Creating and training a DNN model (more specifically, build and train a LSTM model) \n",
    "* Using a trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ts7bKbJgnUrZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python36\\lib\\site-packages (1.3.1)\n",
      "Requirement already satisfied: torchvision in c:\\python36\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: pandas in c:\\python36\\lib\\site-packages (0.25.3)\n",
      "Requirement already satisfied: tensorboard in c:\\python36\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: numpy in c:\\python36\\lib\\site-packages (from torch) (1.17.4)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\python36\\lib\\site-packages (from torchvision) (6.2.1)\n",
      "Requirement already satisfied: six in c:\\python36\\lib\\site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\python36\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\python36\\lib\\site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\python36\\lib\\site-packages (from tensorboard) (0.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python36\\lib\\site-packages (from tensorboard) (3.1.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\python36\\lib\\site-packages (from tensorboard) (1.25.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\python36\\lib\\site-packages (from tensorboard) (3.10.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python36\\lib\\site-packages (from tensorboard) (0.8.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python36\\lib\\site-packages (from tensorboard) (42.0.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\python36\\lib\\site-packages (from tensorboard) (0.33.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\python36\\lib\\site-packages (from tensorboard) (1.7.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\python36\\lib\\site-packages (from tensorboard) (0.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python36\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: cachetools<3.2,>=2.0.0 in c:\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in c:\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python36\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python36\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\python36\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (2.22.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\python36\\lib\\site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python36\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\python36\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.25.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\python36\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\python36\\lib\\site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (2.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 19.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision pandas tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mHIVKwWsbpof"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_NwhW8FmEyl-"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "emWQLgBAn0CS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0th GPU is: GeForce GTX 970M\n"
     ]
    }
   ],
   "source": [
    "# check GPU status\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(\"the {}th GPU is: {}\".format(i, torch.cuda.get_device_name(0)))\n",
    "else:\n",
    "    print(\"Can not find any GPU!!! Please check your colab's setting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRtIMwV3n7Yh"
   },
   "source": [
    "## Building deep learning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg-RvasGmDML"
   },
   "source": [
    "## Basic Introduction\n",
    "This section will introduce all important basic pieces that pytorch offers. You will need this for whatever DNN task you want to deal with.\n",
    "1. Load data\n",
    "2. Build DNN architecture\n",
    "3. Train and evaluate a DNN\n",
    "4. Visualizatoin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q1Wh11Xr4ye_"
   },
   "source": [
    "### Loading Dataset (10 points in total)\n",
    "This is not a function that one has to use pytorch for this purpose. But, the framework of data loading offered by pytorch can really make one's life easier. Let's start.\n",
    "\n",
    "The class, ```torch.utils.data.Dataset```, is the key constructor for createing dataloasers. Any dataloader class must inherit the ```Dataset``` and implement three functions: ```__init__()```, ```__len__()```, ```__getitem__()```.\n",
    "\n",
    "* ```__init__(self, data, **argv)``` takes the input dataset for the  initialization. It will store the data so that other functions in the class can use it. One can also pass other necessory parameters though this initial function. \n",
    "* ```__len__(self)``` returns the size of the input dataset.\n",
    "* ```__getitem__(self, i)``` takes an integer $i$ as input and returns the $i$th sample of the dataset. \n",
    "\n",
    "---\n",
    "\n",
    "For more detail description of the ```Dataset```, please visit https://pytorch.org/docs/stable/data.html.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<font color=red>\n",
    "In the next cell, you will create your first dataloader with following assumptions: \n",
    "\n",
    "1. the dataset is stored as a list of tuples. \n",
    "2. In each tuple, the first element is an input data and the second element is the label of the data. \n",
    "3. Each element can be integer, float number or numpy array. The baseline is all the input data should be the same type and all the output labels should also be consistant on the data types. \n",
    "4. The output of ```__getitem__()``` is a dictionary with two keys: input, output\n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9NQRdn_uqqm"
   },
   "outputs": [],
   "source": [
    "class yourDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data # store the data \n",
    "\n",
    "    def __len__(self):\n",
    "        length = None\n",
    "\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        assert isinstance(i, int)\n",
    "        sample = {'input' : None, \n",
    "                  'output': None}\n",
    "        \n",
    "        return {'input': self.data[i][0], 'output': self.data[i][1],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiAnV57M0sdl"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#\n",
    "#  If your implementation is correct, your function should pass all the following tests\n",
    "#\n",
    "##############################################################\n",
    "random.seed(0)\n",
    "\n",
    "test1_dataset = [(random.random(), random.randint(0,9)) for i in range(5)]\n",
    "test1 = yourDataset(test1_dataset) \n",
    "assert len(test1_dataset) == test1.__len__(), BaseException(\"The len of the dataset is not correct\")\n",
    "for index, value in enumerate(test1_dataset):\n",
    "    input, output = test1.__getitem__(index).values()\n",
    "    assert input == value[0], BaseException(\"The output sample does NOT match with the {}th element of the input data, {},{}\".format(index, input, value[0]))\n",
    "    assert output == value[1], BaseException(\"The output sample does NOT match with the {}th element of the output data, {},{}\".format(index, output, value[1]))\n",
    "\n",
    "\n",
    "base_list = [random.random() for i in range(100)]\n",
    "test2_dataset = [(random.sample(base_list, i), random.randint(0,9)) for i in range(10, 1, -1)]\n",
    "test2 = yourDataset(test2_dataset) \n",
    "assert len(test2_dataset) == test2.__len__(), BaseException(\"The len of the dataset is not correct\")\n",
    "for index, value in enumerate(test2_dataset):\n",
    "    input, output = test2.__getitem__(index).values()\n",
    "    assert input == value[0], BaseException(\"The output sample does NOT match with the {}th element of the input data, {},{}\".format(index, input, value[0]))\n",
    "    assert output == value[1], BaseException(\"The output sample does NOT match with the {}th element of the output data, {},{}\".format(index, output, value[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irfncqR34l_J"
   },
   "source": [
    "### Make loading data easier (15 points in total)\n",
    "Now you already successfully built your first dataloader with pytorch. But there is two inconvenient things: \n",
    "1. It doesn't   generate a randome. \n",
    "2. It can only return one sample at a time. What if we want a batch of samples?\n",
    "\n",
    "You may already find it is a little bit strange that ```__getitem__()``` is a private function that  should **NOT** be directly called by us. \n",
    "\n",
    "The truth is that, this function is designed for ```torch.utils.data.DataLoader```. Please read the introduction of the ```DataLoader``` in here: https://pytorch.org/docs/stable/data.html. <font color=red> And answer following questions in following cells:</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TN-A-ge6VxC4"
   },
   "source": [
    "Read the example code, and answer some questions which will require a little bit knowledge of python itself:\n",
    "```\n",
    "dataset = yourDataset(test1_dataset) \n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1,\n",
    "                        shuffle=True)\n",
    "for index, batch in enumerate(dataloader):\n",
    "    sample = batch\n",
    "    break\n",
    "```\n",
    "1. Check the document that I mentioned earlier, explain the three input parameters for ```torch.utils.data.DataLoader``` in the second line. And what is the output of the ```DataLoader```(hint: the data type of the output)? (5 points)\n",
    "\n",
    "\n",
    "\n",
    "The input parameters to the DataLoader object are as follows:\n",
    "- dataset: A torch.utils.data.DataSet object that the DataLoader can query.\n",
    "- batch_size: The number of data points the DataLoader should load when constructing a query.\n",
    "- shuffle: Should the data loader shuffle the data before beginning the query.\n",
    "\n",
    "The question to about the output of the DataLoader is unclear. If you mean what is the ouptut of the call to the DataLoader constructor then the answer is a torch\n",
    "DataLoader object. If you are asking what is the result of querying the DataLoader, it is a generator that yeilds a batch of data where the specified dictionaries \n",
    "'input' and 'output' in this situation, contain a subset of the data of size 'batch_size'.\n",
    "\n",
    "    \n",
    "    \n",
    "2. When loading any data, always be careful about the meaning of each dimention of the data!!!! All deep learning packages, not only Pytorch, assume you are responsible for making sure the dimentions of your data match the DNN layers' required the input dimentions. Run the code in the next cell. Which dimension of output batch is the batch size? Why?(5 points)\n",
    "\n",
    "The batch size is dimension 0. It is this way because this means that each index in a batch corrisponds to a data point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zHanIUDSeWnL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(1,)\n",
      "batch (input shape): torch.Size([2, 5])\n",
      "batch (output shape): torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "base_list = [np.random.random() for i in range(100)]\n",
    "test4_dataset = [(np.random.randint(0.0, 4.0, 5), np.random.randint(0.0, 10.0, 1)) for i in range(10, 1, -1)]\n",
    "dataset = yourDataset(test4_dataset) \n",
    "print(dataset.__getitem__(0)[\"input\"].shape)\n",
    "print(dataset.__getitem__(0)[\"output\"].shape)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "for index, batch in enumerate(dataloader):\n",
    "    sample = batch\n",
    "    break\n",
    "    \n",
    "\n",
    "input = sample[\"input\"]\n",
    "output = sample[\"output\"]\n",
    "print(\"batch (input shape):\", input.shape)\n",
    "print(\"batch (output shape):\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEniQODvqXlb"
   },
   "source": [
    "#### Dealing with samples with different length\n",
    "When dealing with sequential data, like sentineces and audio recordings, the length of sample is not fix. The problem is that the size of dimention of tensors in one batch much match. The solution is: one have to padding these tensors to make avoid this problem. In ```DataLoader```, parameter ```collate_fn``` take a function which will transform the selected samples into a tensor. By default, it will directly concatenate multiple tensor together. Our new funtion will first pad every tensor to the same shape, then concatenate them together. \n",
    "\n",
    "\n",
    "In the next 3 cells, you will see the consequence of unpadding and padding. \n",
    "\n",
    "<font color=red>\n",
    "Read the 2nd cell carefully, explain why I sorted the samples before padding. (5 points)\n",
    "</font>\n",
    "\n",
    "I am not sure why you sorted the examples. I have removed your sorting in the cell below yours and the code seems to run fine. the padding capabilities of torch should be able to addriess padding issures without the data having to be in order of length. It appears that it does. I see that the first blcok fails because you  are not matching sizes.\n",
    "\n",
    "Please see my code and let me know what I am missing here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zunvlf-xozyZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(9,)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 0. Got 10 and 9 in dimension 1 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:689",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c81777c90541>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_fields'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# namedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_fields'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# namedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 10 and 9 in dimension 1 at C:\\w\\1\\s\\windows\\pytorch\\aten\\src\\TH/generic/THTensor.cpp:689"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "# make sure you understand these code and check the error message\n",
    "base_list = [np.random.random() for i in range(100)]\n",
    "test4_dataset = [(np.random.randint(0, 10, i), np.random.randint(0, 10, 1)) for i in range(10, 1, -1)]\n",
    "dataset = yourDataset(test4_dataset) \n",
    "print(dataset.__getitem__(0)[\"input\"].shape)\n",
    "print(dataset.__getitem__(1)[\"input\"].shape)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "for index, batch in enumerate(dataloader):\n",
    "    sample = batch\n",
    "    break\n",
    "\n",
    "input = sample[\"input\"]\n",
    "output = sample[\"output\"]\n",
    "print(\"batch (input shape):\", input.shape)\n",
    "print(\"batch (output shape):\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fd45zsKFqdp3"
   },
   "outputs": [],
   "source": [
    "def padding(data):\n",
    "    # get target shape\n",
    "    spec_lengths = [i[\"input\"].shape[0] for i in data]\n",
    "    batch_size = len(data)\n",
    "    sorted_index = np.argsort(spec_lengths)\n",
    "\n",
    "    sorted_data = {\"input\": [], \"output\": []}\n",
    "\n",
    "    for i in reversed(sorted_index):\n",
    "        sorted_data[\"input\"].append(torch.from_numpy(data[i][\"input\"]))\n",
    "        sorted_data[\"output\"].append(torch.from_numpy(data[i][\"output\"]))\n",
    "\n",
    "    # nn.utils.rnn.pad_sequence consider the input tensor as either [B,T,F] or [T, B, F], depends on whether patch first\n",
    "    return {\"input\": nn.utils.rnn.pad_sequence(sorted_data[\"input\"], batch_first=True), \n",
    "            \"output\": nn.utils.rnn.pad_sequence(sorted_data[\"output\"], batch_first=True),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def padding(data):\n",
    "    \n",
    "    #### SWAP SHORTER/LONGER POSITION #######\n",
    "    data.reverse()\n",
    "    print(data)\n",
    "    \n",
    "    \n",
    "    # get target shape\n",
    "    spec_lengths = [i[\"input\"].shape[0] for i in data]\n",
    "    batch_size = len(data)\n",
    "    \n",
    "    ####### UNSORTED ######################\n",
    "    sorted_index = range(len(spec_lengths))\n",
    "\n",
    "    sorted_data = {\"input\": [], \"output\": []}\n",
    "\n",
    "    for i in reversed(sorted_index):\n",
    "        sorted_data[\"input\"].append(torch.from_numpy(data[i][\"input\"]))\n",
    "        sorted_data[\"output\"].append(torch.from_numpy(data[i][\"output\"]))\n",
    "\n",
    "    # nn.utils.rnn.pad_sequence consider the input tensor as either [B,T,F] or [T, B, F], depends on whether patch first\n",
    "    ret =  {\"input\": nn.utils.rnn.pad_sequence(sorted_data[\"input\"], batch_first=True), \n",
    "            \"output\": nn.utils.rnn.pad_sequence(sorted_data[\"output\"], batch_first=True),\n",
    "            }\n",
    "    \n",
    "    print(ret)\n",
    "    \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RAyUyeDr7Hd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch (input shape): torch.Size([2, 10])\n",
      "batch (output shape): torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Use padding() instead of the default process. \n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=False, collate_fn=padding)\n",
    "\n",
    "for index, batch in enumerate(dataloader):\n",
    "    sample = batch\n",
    "    break\n",
    "\n",
    "input = sample[\"input\"]\n",
    "output = sample[\"output\"]\n",
    "print(\"batch (input shape):\", input.shape)\n",
    "print(\"batch (output shape):\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V9_Uti5-3jL6"
   },
   "source": [
    "### Variable type\n",
    "In the previous experiment, you might already notice that the ```DataLoader``` converts the data type from numpy array to other type. This is because Pytorch has its own data types and ```DataLoader``` will make sure it's output can be directly fed into the neural network built by Pytorch. \n",
    "\n",
    "Following are some examples about pytorch's tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GV8VDzN76MLW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_array1:  int32\n",
      "torch_array1:  torch.int32\n",
      "np_array2:  float64\n",
      "torch_array2:  torch.float64\n",
      "np_array3:  float32\n",
      "torch_array3:  torch.float32\n"
     ]
    }
   ],
   "source": [
    "# convert a numpy array to a torch.Tensor\n",
    "np_array1 = np.random.randint(0, 4, (3,3))\n",
    "torch_array1 = torch.from_numpy(np_array1)\n",
    "print(\"np_array1: \", np_array1.dtype)\n",
    "print(\"torch_array1: \", torch_array1.dtype)\n",
    "\n",
    "np_array2 = np.random.random_sample((3,3))\n",
    "torch_array2 = torch.from_numpy(np_array2)\n",
    "print(\"np_array2: \", np_array2.dtype)\n",
    "print(\"torch_array2: \", torch_array2.dtype)\n",
    "\n",
    "np_array3 = np.random.random_sample((3,3)).astype(np.float32)\n",
    "torch_array3 = torch.from_numpy(np_array3)\n",
    "print(\"np_array3: \", np_array3.dtype)\n",
    "print(\"torch_array3: \", torch_array3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lLQGwiEz8edJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_tensor_int:  torch.int64\n",
      "torch_tensor_float:  torch.float64\n"
     ]
    }
   ],
   "source": [
    "# convert a torch.Tensor from int64 to float64\n",
    "torch_tensor_int = torch.tensor([1,1])\n",
    "torch_tensor_float = torch_tensor_int.double()\n",
    "print(\"torch_tensor_int: \", torch_tensor_int.dtype)\n",
    "print(\"torch_tensor_float: \", torch_tensor_float.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zkWtI7kmlTxq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_tensor_int:  torch.int64 cuda:0\n",
      "torch_tensor_float:  torch.float32 cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2.],\n",
       "        [2., 2., 2.],\n",
       "        [2., 2., 2.]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch will automatically convert one type to another, if these are in the same device (GPU or CPU)\n",
    "# here is an example of float32.cpu and float32.cuda\n",
    "torch_tensor_int  = torch.ones((3,3), dtype=int).to(\"cuda\")\n",
    "torch_tensor_float = torch_tensor_int.float() # copy a cpu tensor to gpu\n",
    "\n",
    "print(\"torch_tensor_int: \", torch_tensor_int.dtype,  torch_tensor_int.device) \n",
    "print(\"torch_tensor_float: \",torch_tensor_float.dtype,  torch_tensor_float.device) \n",
    "\n",
    "torch_tensor_float + torch_tensor_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gS440QSZ9_ur"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch_tensor_cpu:  torch.float32 cpu\n",
      "torch_tensor_gpu1:  torch.float32 cuda:0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected device cpu but got device cuda:0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d7d07f21cbcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"torch_tensor_gpu1: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch_tensor_gpu1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtorch_tensor_gpu1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtorch_tensor_cpu\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch_tensor_gpu1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: expected device cpu but got device cuda:0"
     ]
    }
   ],
   "source": [
    "# pytorch will not automatically convert one type to another, if these not are in the same device (GPU or CPU)\n",
    "# here is an example of float32.cpu and float32.cuda\n",
    "torch_tensor_cpu  = torch.ones((3,3))\n",
    "torch_tensor_gpu1 = torch_tensor_cpu.to(\"cuda\") # copy a cpu tensor to gpu\n",
    "\n",
    "print(\"torch_tensor_cpu: \", torch_tensor_cpu.dtype,  torch_tensor_cpu.device) \n",
    "print(\"torch_tensor_gpu1: \",torch_tensor_gpu1.dtype,  torch_tensor_gpu1.device) \n",
    "\n",
    "torch_tensor_cpu + torch_tensor_gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LTpgd_I7ZzUo"
   },
   "source": [
    "### DNN Model (60 points in total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eOcU0IlArQYW"
   },
   "source": [
    "In this part, you will deal with a simple deep learning task --- counting. That is, the neural net takes a sequence of $1$s as input, it will learn to generate same number of $2$s as output. The formal definition of the task is: give a input sequence $41^n3$, where 4 is the start symble, 3 is the delimiter and n $1$s are between 4 and 3, the neural network will output a sequence $2^n0$, where 0 is the stop symble.  \n",
    "\n",
    "After this, we will deal with another more complex task -- copy which will be discussed later this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0StsVv6Vqwba"
   },
   "source": [
    "#### Building DNN architecture\n",
    "The first step of training your own model is defining the architecture.\n",
    "Here is an example of a small RNN defined in PyTorch.\n",
    "```\n",
    "class exampleRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(exampleRNN, self).__init__()\n",
    "        self.fc0 = torch.nn.Embedding(5, 4)\n",
    "        self.rnn_layer = torch.nn.LSTM(input_size=4, \n",
    "                                       hidden_size=10, \n",
    "                                       num_layers=1, \n",
    "                                       bidirectional=False, \n",
    "                                       batch_first=True)\n",
    "\n",
    "        self.dropout = torch.nn.Dropout(0.4)\n",
    "        self.fc1 = torch.nn.Linear(10, 5)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, initial_hidden):\n",
    "        x1 = self.fc0(x)\n",
    "        x2, hidden = self.rnn_layer(x1, initial_hidden)\n",
    "        x3 = self.dropout(x2)\n",
    "        x4 = self.fc1(x3)\n",
    "        x5 = self.softmax(x4)\n",
    "        return x5, hidden\n",
    "```\n",
    "\n",
    "Above is a RNN architecture, all layers are initialized in ```__init___()```. And, ```forward()``` defines how those layers stack together when process the input data. You can find all those layers' description at [here](https://pytorch.org/docs/stable/index.html). <font color=red>Check the description of embedding layer, lstm layer and logsoftmax layer and answer following questions:\n",
    "</font>\n",
    "* For embedding layer, if the shape of x is (1, 8, 5), what should be the shape of x1? And what is the meaning of each dimension? More importantly, what is the data type that this tensor x should be. (3 points)\n",
    "<font color=blue> \n",
    "The output shape should be (1, 8, 4). The dimensions are (# batches, # data points, # features). I dont understand the last question: float32? torch.Tensor? Sequence embedding?\n",
    "</font>\n",
    "\n",
    "* For lstm layer:\n",
    "    1. How many elements are in initial_hidden? (2 points)\n",
    "    <font color=blue> \n",
    "    \\# Your answer here\n",
    "    </font>\n",
    "    2. If the shape of x1 is (1, 8, 4), what is the shape of each element in initial_hidden and the shape of ```x2```? (2 points)\n",
    "    <font color=blue> \n",
    "    10\n",
    "    </font>\n",
    "    3. Under the same assumption, what is the shape of the element in ```hidden```? (2 points)\n",
    "    <font color=blue> \n",
    "    (# batches, # datapoints, 10)\n",
    "    </font>\n",
    "    4. under the same assumption, what is the relationship between ```x2[:, -1, :]``` and ```hidden[0]```? (4 points)\n",
    "    <font color=blue> \n",
    "    x2[:, -1, :] == hidden[0]\n",
    "    </font>\n",
    "\n",
    "* For log softmax layer, what is the meaning of ```dim=-1```? What is each dimension's meaning of the output? (5 points)\n",
    "<font color=blue> \n",
    "Select the last dim, ie the columns that are your features and not the different datapoints in a batch.\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l2K425i71Ct_"
   },
   "source": [
    "#### One step before train a DNN model\n",
    "Before start train a model, we still need to decide the loss function and the optimization function. \n",
    "Similar to the example of build dnn architecture, read the code carefully and answer some questions after you read the example code.\n",
    "\n",
    "```\n",
    "(1) simple_model = exampleRNN()\n",
    "(2) loss_fn = torch.nn.NLLLoss()\n",
    "(3) optimizer = torch.optimizer.Adam(simple_model.parameters(), lr=1e-2)\n",
    "```\n",
    "1. Which line initializes the DNN model?(1 points)\n",
    "<font color=blue> \n",
    "(1) simple_model = exampleRNN()\n",
    "</font>\n",
    "2. Which line specifies the loss function? (1 points)\n",
    "<font color=blue> \n",
    "(2) loss_fn = torch.nn.NLLLoss()\n",
    "</font>\n",
    "3. Which line specifies the optimization function? And what is the meaning of each parameter? (5 points)\n",
    "<font color=blue> \n",
    "(3) optimizer = torch.optimizer.Adam(simple_model.parameters(), lr=1e-2: the first is the parameters to update on the backward pass, the second is what the graident should be multiplied by when updating (learning rate).\n",
    "</font>\n",
    "4. If the loss function is ```torch.nn.CrossEntropyLoss```, is there anything I need modify in the RNN architecture? If so, how should I modify it? (5 points)\n",
    "<font color=blue> \n",
    "You should remove the log softmax layer at the output.\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9iKJszXExbKf"
   },
   "source": [
    "#### Example1: Train a model for counting task\n",
    "Here we will put every pieces together to train a model. Make sure that ```youDataSampler()``` and ```padding()``` works fine. We introduced ```padding()``` earlier. Complete the function ```generate_initial_hidden()```. And run the experiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGflOjH-DHv8"
   },
   "outputs": [],
   "source": [
    "class exampleRNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(exampleRNN, self).__init__()\n",
    "        self.fc0 = torch.nn.Embedding(num_embeddings=5, embedding_dim=4)\n",
    "        self.rnn_layer = torch.nn.LSTM(input_size=4, hidden_size=10, num_layers=1, bidirectional=False, batch_first=True)\n",
    "        self.dropout = torch.nn.Dropout(0.4)\n",
    "        self.fc1 = torch.nn.Linear(10, 5)\n",
    "        self.softmax = torch.nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.fc0(x)\n",
    "        x2, hidden = self.rnn_layer(x, hidden)\n",
    "        x3 = self.dropout(x2)\n",
    "        x4 = self.fc1(x3)\n",
    "        x5 = self.softmax(x4)\n",
    "        return x5, hidden\n",
    "\n",
    "\n",
    "def data_generation():\n",
    "    np.random.seed(0)\n",
    "    data = []\n",
    "    for i in range(10000):\n",
    "        length = i % 10 + 1\n",
    "        seq = np.zeros(length*2+3, dtype=int)\n",
    "\n",
    "        seq[0] = 4\n",
    "        seq[1:length+1] = 1 \n",
    "        seq[length+1] = 3\n",
    "        seq[length+2:-1] = 2\n",
    "        seq[-1] = 0\n",
    "\n",
    "        input = copy.deepcopy(seq[:-1]).astype(np.int64)\n",
    "        output = copy.deepcopy(seq[1:]).astype(np.int64)\n",
    "        data.append((input, output))\n",
    "\n",
    "    return np.array(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9h_q0E77Clsq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64),\n",
       "       array([1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0],\n",
       "      dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize the data\n",
    "data = data_generation()\n",
    "data[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMiQAQbjtC5B"
   },
   "outputs": [],
   "source": [
    "# Most of the code are ready\n",
    "# BUT, there are still several line of code need your work!!\n",
    "\n",
    "def generate_initial_hidden(batch_size, device=\"cpu\"):\n",
    "    hidden = []\n",
    "    # Both h_0 and c_0 should be initialized as zero tensors\n",
    "    hidden = [torch.zeros((1, batch_size, 10)).to(device), \n",
    "              torch.zeros((1, batch_size, 10)).to(device)]\n",
    "    return hidden\n",
    "\n",
    "def output_transpose(output):\n",
    "    output_hat = None\n",
    "    output_hat = output.transpose(1, 2)\n",
    "    return output_hat\n",
    "\n",
    "def char_generation(model, seq, max_len=100, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    # seq = np.eye(5, dtype=np.float32)[seq.reshape(-1)]\n",
    "    input_seq = torch.from_numpy(seq)\n",
    "    input_seq = input_seq.unsqueeze(0).to(device)\n",
    "    hidden = [torch.zeros([1, 1, 10]).to(device), \n",
    "              torch.zeros([1, 1, 10]).to(device)]\n",
    "    \n",
    "    counting = []\n",
    "    input_char = input_seq\n",
    "    for i in range(max_len):\n",
    "        new_char_prob, hidden = model(input_char.to(device), hidden)\n",
    "        new_char_prob = new_char_prob[:, -1]\n",
    "        new_char = torch.distributions.categorical.Categorical(logits=new_char_prob).sample() # output is a Long tensor\n",
    "        new_char = new_char.item() # transform to numpy \n",
    "        input_char = torch.zeros(1, 1).type_as(input_char).fill_(new_char)\n",
    "        counting.append(new_char)\n",
    "        if new_char == 0:\n",
    "            return counting\n",
    "    return counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3S5L3xkJydER"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.23022131621837616\n",
      "eval loss: 0.16291641082727548\n",
      "train loss: 0.1874101310968399\n",
      "eval loss: 0.12775074054646973\n",
      "train loss: 0.14346323907375336\n",
      "eval loss: 0.12377344952388243\n",
      "train loss: 0.1373668760061264\n",
      "eval loss: 0.11923109977082773\n",
      "train loss: 0.14196111261844635\n",
      "eval loss: 0.11707423367735112\n",
      "train loss: 0.13310842216014862\n",
      "eval loss: 0.11554426654721751\n",
      "train loss: 0.12435323745012283\n",
      "eval loss: 0.11498771009571625\n",
      "train loss: 0.15274640917778015\n",
      "eval loss: 0.11442543509783167\n",
      "train loss: 0.1417730301618576\n",
      "eval loss: 0.1129363789928682\n",
      "train loss: 0.12454812973737717\n",
      "eval loss: 0.11529648808216808\n",
      "train loss: 0.11909613013267517\n",
      "eval loss: 0.11313263748330299\n",
      "train loss: 0.16317789256572723\n",
      "eval loss: 0.11310458822984888\n",
      "train loss: 0.1393606811761856\n",
      "eval loss: 0.1130279762049516\n",
      "train loss: 0.12153904139995575\n",
      "eval loss: 0.11255208846896586\n",
      "train loss: 0.14302580058574677\n",
      "eval loss: 0.11281618585038666\n",
      "train loss: 0.12373407930135727\n",
      "eval loss: 0.11252223380436802\n",
      "train loss: 0.1290806382894516\n",
      "eval loss: 0.11296781246559788\n",
      "train loss: 0.13685549795627594\n",
      "eval loss: 0.11233222089482076\n",
      "train loss: 0.15732935070991516\n",
      "eval loss: 0.11259754163899807\n",
      "train loss: 0.12003562599420547\n",
      "eval loss: 0.11037153005599976\n"
     ]
    }
   ],
   "source": [
    "simple_model = exampleRNN()\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(simple_model.parameters(), lr=1e-3)\n",
    "\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train_data = data[msk]\n",
    "val_data = data[~msk]\n",
    "\n",
    "train_dataloader = DataLoader(yourDataset(train_data), batch_size=10, shuffle=True, collate_fn=padding)\n",
    "val_dataloader = DataLoader(yourDataset(val_data), batch_size=10, shuffle=True, collate_fn=padding)\n",
    "\n",
    "# if you want change to GPU mode, you just need to let device = \"cuda:0\" where 0 indicate the first gpu in your computer.\n",
    "device='cuda' \n",
    "simple_model.to(device)\n",
    "for i in range(20):\n",
    "    # Sets this simple_model in training mode. Just need one function\n",
    "    simple_model.train()\n",
    "\n",
    "    for index, batch in enumerate(train_dataloader):\n",
    "        input = batch[\"input\"].to(device)\n",
    "        output = batch[\"output\"].to(device)\n",
    "        hidden = generate_initial_hidden(batch_size=input.shape[0], device=device)\n",
    "\n",
    "        simple_model.zero_grad()\n",
    "\n",
    "        output_hat, _ = simple_model(input, hidden)\n",
    "        output_hat = output_transpose(output_hat)\n",
    "        # compute loss\n",
    "        train_loss = loss_fn(output_hat, output)\n",
    "        # compute gradient\n",
    "        train_loss.backward()\n",
    "        # weights update\n",
    "        optimizer.step()\n",
    "\n",
    "    val_loss = []\n",
    "    # Set the simple_model in evaluation mode. Just need one function.\n",
    "    simple_model.eval()\n",
    "    \n",
    "    for index, batch in enumerate(val_dataloader):\n",
    "        input = batch[\"input\"].to(device)\n",
    "        output = batch[\"output\"].to(device)\n",
    "        hidden = generate_initial_hidden(batch_size=input.shape[0], device=device)\n",
    "\n",
    "        output_hat, _ = simple_model(input, hidden)\n",
    "        output_hat = output_transpose(output_hat)\n",
    "        loss = loss_fn(output_hat, output)\n",
    "        val_loss.append(loss.item())\n",
    "        \n",
    "    print(\"train loss:\", train_loss.item())\n",
    "    print(\"eval loss:\", np.mean(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PQSMe-kIsLoP"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-cf18850c2c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test, case 1: when n less than 10, which is the maximum length in our training examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-4c57f2f05d91>\u001b[0m in \u001b[0;36mchar_generation\u001b[1;34m(model, seq, max_len, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0minput_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mnew_char_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_char\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mnew_char_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_char_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnew_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_char_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output is a Long tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-91e287146fb0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m         return F.embedding(\n\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "# test, case 1: when n less than 10, which is the maximum length in our training examples\n",
    "device='cuda'\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHbS-gX1iFyK"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-8a3caa2a0bb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test, case 2: when n is larger than 10.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-4c57f2f05d91>\u001b[0m in \u001b[0;36mchar_generation\u001b[1;34m(model, seq, max_len, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0minput_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_seq\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mnew_char_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_char\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mnew_char_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_char_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mnew_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_char_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# output is a Long tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-91e287146fb0>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m         return F.embedding(\n\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.IntTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "# test, case 2: when n is larger than 10.\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))\n",
    "print(char_generation(simple_model, np.array([4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3]), device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0e1mLNSCA0zB"
   },
   "source": [
    "#### A useful visualization tool\n",
    "We just finish the first training task. In this task, we just print out the training loss and evaluation loss. What if we want something else? For example, the output of a specific input, or the curve of training loss while the model is still training. Instead of writting by ourself, we can also use Tensorboard.\n",
    "Tensorborad is a visualization tool designed by Google. Even though Google only offers example on using tensorflow to interact with tensorboard. Tensorboard can be used by Pytorch or any other deep learning platform. \n",
    "\n",
    "Pytorch offers a group of API to saving outputs as a tensorborad readable format. Next cell is an intuitive example of how to draw scaler and output text. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZXTf-s8-3P-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2352), started 1:08:52 ago. (Use '!kill 2352' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# it seems there is some problem on delete directory in colab\n",
    "# you need to de\n",
    "if os.path.isdir(\"runs\"):\n",
    "    shutil.rmtree(\"runs\")\n",
    "\n",
    "# create a tensorboard writer instance. \n",
    "exp_writer = SummaryWriter(flush_secs=10)\n",
    "\n",
    "%tensorboard --logdir runs\n",
    "for n_iter in range(100):\n",
    "    exp_writer.add_scalar('Loss/train', np.random.random(), n_iter)\n",
    "    exp_writer.add_scalar('Loss/test', np.random.random(), n_iter)\n",
    "    exp_writer.add_text(\"train\", \"{}th iter: hello \\n\\n\".format(n_iter), global_step=n_iter)\n",
    "exp_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hP_A4mugZYcl"
   },
   "outputs": [],
   "source": [
    "def result_recording(tensorboard_writer, train_loass, test_loss, n_iter):\n",
    "    tensorboard_writer.add_scalar('Loss/train', train_loss, n_iter)\n",
    "    tensorboard_writer.add_scalar('Loss/test', test_loss, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hkMEkfz9hz4"
   },
   "source": [
    "#### Saving and Loading a trained model\n",
    "The example in the next cell is how to save and load a trained model's weights. [Here](https://pytorch.org/tutorials/beginner/saving_loading_models.html) offers very detail explaination about how pytorch saves and loads model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zrsa7Lrc-Au_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving a trained model's weights to a given path\n",
    "torch.save(simple_model.state_dict(), \"./simple_model.gpu\")\n",
    "\n",
    "# load a trained model's weights from given path. Be Careful about the weights' type difference. \n",
    "# As we already seen that cuda_tensor and cpu_tensor are not compatable.\n",
    "simple_model2 = exampleRNN()\n",
    "simple_model2.load_state_dict(torch.load(\"./simple_model.gpu\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IHWW5iZNLAj7"
   },
   "source": [
    "#### Another task: copy\n",
    "\n",
    "Counting is a relatively easy task because the pattern is streatforward: except the start symbol and end symbol, $1$s only appears before the delimiter while $2$s appears after the delimiter all the time. The result looks good even without any hyperparameter tunning.\n",
    "\n",
    "Now, let's try a more complex task: copy. The model takes a sequence, which is a random combination of $1$s and $2$s, as input and it should output the exact same sequence. For example, if the input is \"4121223\", the output should be \"121220\", where 4 is the start symble, 0 is the end symble and 3 is the delimiter. Comparing with counting, LSTM needs to learn a more complex pattern in copy. As a consequence, more data is required to help the model summarize the pattern. \n",
    "\n",
    "Since we alreay have some experience on the whole pipeline in previous exercise. This time, we will focus on reorganizing the code to make it easier to tune the hyperparameter. After all, it is unlikely that we can get a good set of hyperparameters with first guess. In the next cell, you are required to implement some functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-VvDx5uIwCd"
   },
   "source": [
    "##### Complete the code (15 points, 5 for each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wq8mCyUnTqF3"
   },
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, embedding_size, lstm_hidden_size, lstm_num_layers, lstm_bidirectional, lstm_dropout, last_dropout):\n",
    "        '''\n",
    "        Instead of set fixed hyperparamters, we may want change some hyper parameter while not change any code in the class.\n",
    "        I already define the input parameters. You are responsible for create DNN layers based on them.\n",
    "        '''\n",
    "        super(CharRNN, self).__init__()\n",
    "        assert isinstance(lstm_bidirectional, bool)\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_num_layers = lstm_num_layers\n",
    "        self.lstm_bidirectional = lstm_bidirectional\n",
    "        self.lstm_dropout = lstm_dropout\n",
    "        self.last_dropout = last_dropout\n",
    "\n",
    "        #################### your code start ############################\n",
    "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size=embedding_size, \n",
    "                            hidden_size=lstm_hidden_size, \n",
    "                            num_layers=lstm_num_layers,\n",
    "                            bidirectional=lstm_bidirectional,\n",
    "                            dropout=lstm_dropout)\n",
    "        self.fc = nn.Linear(lstm_hidden_size, input_size) \n",
    "        self.dropout = nn.Dropout()\n",
    "        #################### your code ends ############################\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=-1) \n",
    "\n",
    "\n",
    "    def forward(self, input, initial_hidden):\n",
    "        \n",
    "        print(\"input: \", input.shape)\n",
    "        print(\"init hidden: \", initial_hidden)\n",
    "        \n",
    "        x = self.embedding(input)\n",
    "        \n",
    "        print(\"x: \", x.shape)\n",
    "        \n",
    "        \n",
    "        x, hidden = self.lstm(x, initial_hidden)\n",
    "\n",
    "        print(\"x: \", x.shape)\n",
    "        print(\"hidden: \", hidden.shape)\n",
    "        \n",
    "        outputs = x\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.fc(outputs)\n",
    "        outputs = self.softmax(outputs)\n",
    "\n",
    "        y = outputs \n",
    "        \n",
    "        return y, hidden\n",
    "\n",
    "\n",
    "class dnn_operations(object):\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "\n",
    "    def train(self, dataloader, device=\"cpu\"):\n",
    "        ################your code start ########################\n",
    "        # This function is based on counting task's training process.\n",
    "        # takes the training dataset as input. \n",
    "        # Train the model.\n",
    "        # And, return average loss overall samples in the dataset\n",
    "        # DON'T forget set the model to training mode. \n",
    "\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        for index, batch in enumerate(dataloader):\n",
    "            input = batch[\"input\"].to(device)\n",
    "            output = batch[\"output\"].to(device)\n",
    "            hidden = generate_initial_hidden(batch_size=input.shape[0], device=device)\n",
    "            hidden = np.array(hidden)\n",
    "            self.model.zero_grad()\n",
    "\n",
    "            output_hat, _ = self.model(input, hidden)\n",
    "            output_hat = output_transpose(output_hat)\n",
    "            # compute loss\n",
    "            train_loss = self.loss_fn(output_hat, output)\n",
    "            # compute gradient\n",
    "            train_loss.backward()\n",
    "            # weights update\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return self.train_loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        ##################your code end ######################\n",
    "        return loss.item()\n",
    "\n",
    "    def eval(self, dataloader, device=\"cpu\"):\n",
    "        ################ your code start ########################\n",
    "        # This function is based on counting task's evaluation process.\n",
    "        # takes the evaluation dataset as input. \n",
    "        # Return the average loss overall samples in the dataset\n",
    "        # DON'T forget set the model to evaluation mode. \n",
    "\n",
    "        val_loss = []\n",
    "        # Set the simple_model in evaluation mode. Just need one function.\n",
    "        self.model.eval()\n",
    "\n",
    "        for index, batch in enumerate(val_dataloader):\n",
    "            input = batch[\"input\"].to(device)\n",
    "            output = batch[\"output\"].to(device)\n",
    "            hidden = generate_initial_hidden(batch_size=input.shape[0], device=device)\n",
    "\n",
    "            output_hat, _ = self.model(input, hidden)\n",
    "            output_hat = output_transpose(output_hat)\n",
    "            loss = self.loss_fn(output_hat, output)\n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        ##################your code end ######################\n",
    "        return np.mean(val_loss)\n",
    "\n",
    "    def generate_initial_hidden(self, batch_size, device):\n",
    "\n",
    "        initial_hidden = [torch.zeros([self.model.lstm_num_layers * (int(self.model.lstm_bidirectional) + 1), batch_size, self.model.lstm_hidden_size]).to(device), \n",
    "                          torch.zeros([self.model.lstm_num_layers * (int(self.model.lstm_bidirectional) + 1), batch_size, self.model.lstm_hidden_size]).to(device)]\n",
    "        return np.array(initial_hidden)\n",
    "\n",
    "    def char_generation(self, seq, max_len=100, device=\"cpu\"):\n",
    "        self.model.eval()\n",
    "        input_seq = torch.from_numpy(seq)\n",
    "        input_seq = input_seq.unsqueeze(0).to(device)\n",
    "        hidden = self.generate_initial_hidden(1, device=device)\n",
    "\n",
    "        outputs = []\n",
    "        input_char = input_seq\n",
    "        for i in range(max_len):\n",
    "            new_char_prob, hidden = self.model(input_char.to(device), hidden)\n",
    "            new_char_prob = new_char_prob[:, -1]\n",
    "            new_char = torch.distributions.categorical.Categorical(logits=new_char_prob).sample() # output is a Long tensor\n",
    "            new_char = new_char.item() # transform to numpy \n",
    "            input_char = torch.zeros(1, 1).type_as(input_char).fill_(new_char)\n",
    "            outputs.append(new_char)\n",
    "\n",
    "            if new_char == 0:\n",
    "                return outputs\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jpn0FXJisdqR"
   },
   "outputs": [],
   "source": [
    "def data_generation_forcoping(num_samples=10000):\n",
    "    np.random.seed(0)\n",
    "    data = []\n",
    "    for i in range(num_samples):\n",
    "        length = i % 10 + 1\n",
    "        seq = np.zeros(length*2+3, dtype=int)\n",
    "\n",
    "        temp = np.random.randint(1,3, length)\n",
    "        seq[0] = 4\n",
    "        seq[1:length+1] = copy.deepcopy(temp)\n",
    "        seq[length+1] = 3\n",
    "        seq[length+2:-1] = copy.deepcopy(temp)\n",
    "        seq[-1] = 0\n",
    "\n",
    "        input = copy.deepcopy(seq[:-1]).astype(np.int64)\n",
    "        output = copy.deepcopy(seq[1:]).astype(np.int64)\n",
    "        data.append((input, output))\n",
    "\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8RiP37WZtDRr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([4, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 3, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2],\n",
       "      dtype=int64),\n",
       "       array([1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 3, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 0],\n",
       "      dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_coping = data_generation_forcoping(num_samples=100000)\n",
    "data_coping[109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VIMyeVcEsb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input:  torch.Size([20, 22])\n",
      "init hidden:  [tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')\n",
      " tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], device='cuda:0')]\n",
      "x:  torch.Size([20, 22, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 22, 14), got (1, 20, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-3b55ade3254c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperations_for_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0meval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moperations_for_copy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m#result_recording(writer_coping, train_loss, eval_loss, i)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-dbafba3890b3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataloader, device)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0moutput_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[0moutput_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_transpose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;31m# compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-76-dbafba3890b3>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, initial_hidden)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    562\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 564\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m         self.check_hidden_size(hidden[0], expected_hidden_size,\n\u001b[1;32m--> 500\u001b[1;33m                                'Expected hidden[0] size {}, got {}')\n\u001b[0m\u001b[0;32m    501\u001b[0m         self.check_hidden_size(hidden[1], expected_hidden_size,\n\u001b[0;32m    502\u001b[0m                                'Expected hidden[1] size {}, got {}')\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;31m# type: (Tensor, Tuple[int, int, int], str) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 22, 14), got (1, 20, 10)"
     ]
    }
   ],
   "source": [
    "# model initialization\n",
    "simple_model_coping = CharRNN(input_size=5, \n",
    "                              embedding_size=4, \n",
    "                              lstm_hidden_size=14, \n",
    "                              lstm_num_layers=1, \n",
    "                              lstm_bidirectional=False, \n",
    "                              lstm_dropout=0, \n",
    "                              last_dropout=0.5)\n",
    "\n",
    "loss_fn_coping = torch.nn.NLLLoss()\n",
    "optimizer_coping = torch.optim.Adam(simple_model_coping.parameters(), lr=1e-3)\n",
    "\n",
    "# if you want change to GPU mode, you just need to let device = \"cuda:0\" where 0 indicate the first gpu in your computer.\n",
    "device='cuda' \n",
    "simple_model_coping.to(device)\n",
    "\n",
    "operations_for_copy = dnn_operations(model=simple_model_coping, loss_fn=loss_fn_coping, optimizer=optimizer_coping)\n",
    "\n",
    "# loading data\n",
    "msk_coping = np.random.rand(len(data_coping)) < 0.8\n",
    "train_data_coping = data_coping[msk_coping]\n",
    "val_data_coping = data_coping[~msk_coping]\n",
    "\n",
    "train_dataloader = DataLoader(yourDataset(train_data_coping), batch_size=20, shuffle=True, collate_fn=padding)\n",
    "val_dataloader = DataLoader(yourDataset(val_data_coping), batch_size=20, shuffle=True, collate_fn=padding)\n",
    "\n",
    "\n",
    "# create a tensorboard writer instance. \n",
    "#writer_coping = SummaryWriter(flush_secs=10)\n",
    "\n",
    "#%tensorboard --logdir runs\n",
    "    \n",
    "for i in range(20):\n",
    "    print(i)\n",
    "    train_loss = operations_for_copy.train(dataloader=train_dataloader, device=device)\n",
    "    eval_loss = operations_for_copy.eval(dataloader=train_dataloader, device=device)\n",
    "    #result_recording(writer_coping, train_loss, eval_loss, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8djXL2Fu9MO"
   },
   "outputs": [],
   "source": [
    "# all the mode\n",
    "print(operations_for_copy.char_generation(np.array([4, 1, 2, 2, 1, 2, 1, 3]), device=device))\n",
    "print(operations_for_copy.char_generation(np.array([4, 2, 1, 2, 2, 2, 2, 1, 3]), device=device))\n",
    "print(operations_for_copy.char_generation(np.array([4, 2, 2, 1, 2, 1, 2, 2, 1, 3]), device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9FvEGi5jOqwB"
   },
   "outputs": [],
   "source": [
    "# sequence longer than 10\n",
    "print(operations_for_copy.char_generation(np.array([2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 3]), device=device))\n",
    "print(operations_for_copy.char_generation(np.array([2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 3]), device=device))\n",
    "print(operations_for_copy.char_generation(np.array([2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 3]), device=device))\n",
    "print(operations_for_copy.char_generation(np.array([2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 3]), device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_p__rcoYAmiE"
   },
   "source": [
    "##### Some extra experiments (15 points)\n",
    "<font color=red>\n",
    "Copy the experiment to new cells, but change the hyperparameters of the model. You can changes the lstm hidden size to be 10 or 20. OR, you can use more than one lstm layers. OR, some other hyperparameters you find interesting. \n",
    "Report your findings. Hopefully, this experiment should offer you some experience on tuning the hyperparameters.\n",
    "</font>\n",
    "\n",
    "\n",
    "<font color=blue>\n",
    "Your report\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RBvraOLiFzSX"
   },
   "source": [
    "## CharRNN on generation (15 points in total)\n",
    "\n",
    "### CharRNN\n",
    "Basically, CharRNN is just a regular recurrent neural network. One can use any rnn layer to build this network, e.g. GRU, LSTM. The word \"Char\" indicates that the input unit is a single character, like 'a', '\\n', '$\\alpha$'. Using it for code generation is a perfect example to show how LSTM can learn some long term dependencies while it does not simply memorise every thing. There are other cool experiments about CharRNN in [here](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). \n",
    "\n",
    "### Task (15 points)\n",
    "This section is more focus on experiments. I will offer you a compelet example on training a CharRNN on C++ code generation. Your task is train a model with some other data. You can modify the code that I offers. Tune the hyperparameters might be a necessory step. [Here are some interesting data you can try](https://cs.stanford.edu/people/karpathy/char-rnn/). This is also where I download the linux code. Working on some small size data is highly recommended.\n",
    "\n",
    "Report your training result. Can you find some clue that can distinguish the real text and generated text?\n",
    "<font color=blue>\n",
    "your report\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwkR_7-RlQXS"
   },
   "source": [
    "### Prepare Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3Y73ZFqACUe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file linux_code already exists.\n"
     ]
    }
   ],
   "source": [
    "!mkdir linux_code\n",
    "!wget https://cs.stanford.edu/people/karpathy/char-rnn/linux_input.txt -O linux_code/linux_input.txt\n",
    "!ls linux_code\n",
    "filepath=\"linux_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGdoeh_almbk"
   },
   "outputs": [],
   "source": [
    "def generate_data(dirpath, segment_length=36):\n",
    "    \"\"\"\n",
    "    this function will load the text file \n",
    "    and generate text segments with given length limitation\n",
    "   \n",
    "    parameters:\n",
    "        dirpath: path to the text file\n",
    "        segment_length: length of the text segment\n",
    "    Outputs:\n",
    "        1. A numpy array of tuples. In a tuple, the first element contains \n",
    "           the first segment_length-1 of characters, the last contains the \n",
    "           last segment_length-1 of characters. Like this example (segment_length=100):   \n",
    "           ('/*\\n * linux/kernel/irq/autoprobe.c\\n *\\n * Copyright (C) 1992, 1998-2004 Linus Torvalds, Ingo Molnar\\n',\n",
    "            '*\\n * linux/kernel/irq/autoprobe.c\\n *\\n * Copyright (C) 1992, 1998-2004 Linus Torvalds, Ingo Molnar\\n ')\n",
    "        2. the dictionary for mapping each character to a unique index. \n",
    "        3. the reversed dictionary that mapping the index to character\n",
    "    \"\"\"\n",
    "\n",
    "    data = None\n",
    "    char2index = None\n",
    "    index2char = None\n",
    "    filenames = []\n",
    "    for _,_,fs in os.walk(dirpath):\n",
    "        filenames.extend(fs)\n",
    "    \n",
    "    data = []\n",
    "    chars = set([])\n",
    "    for fname in filenames:\n",
    "        with open(os.path.join(dirpath, fname), 'r', encoding=\"utf8\", errors='ignore') as f:\n",
    "            text = f.read(segment_length)\n",
    "            while text:\n",
    "                input = text[:-1]\n",
    "                output = text[1:]\n",
    "                data.append((input, output))\n",
    "                chars |= set(text)\n",
    "                text = f.read(segment_length)\n",
    "\n",
    "    data = np.array(data)\n",
    "    char_list = sorted(list(chars))\n",
    "    char2index = {char:index for index, char in enumerate(char_list)}\n",
    "    index2char = {v:k  for k, v in char2index.items()}\n",
    "    assert isinstance(data, np.ndarray)\n",
    "    for i, c in index2char.items():\n",
    "        assert char2index[c] == i \n",
    "    return data, char2index, index2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OkMFdEdY3wRK"
   },
   "outputs": [],
   "source": [
    "# visualize your output. Make sure the output is correct\n",
    "data, char2index, index2char = generate_data(filepath, segment_length=100)\n",
    "data[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "832_kZhvFwzt"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, char2index):\n",
    "        \"\"\"\n",
    "        Input parameters\n",
    "            data: a list of tuple. The first element in a tuple should be the input for the DNN, the second one should be the output\n",
    "            char2index: map characters to index\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.char2index = char2index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.data[idx]\n",
    "        input = None\n",
    "        output = None\n",
    "        # transform selected text into the index list\n",
    "\n",
    "        input  = np.array([self.char2index[i] for i in instance[0]], dtype=np.int64) \n",
    "        output = np.array([self.char2index[i] for i in instance[1]], dtype=np.int64)\n",
    "        \n",
    "        assert isinstance(input, np.ndarray)\n",
    "        assert isinstance(output, np.ndarray)\n",
    "        sample = {'input' : input, \n",
    "                  'output': output}\n",
    "        return sample\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ulOtwHeKs9D7"
   },
   "outputs": [],
   "source": [
    "# visualize your output. Make sure the output is correct\n",
    "test_text = TextDataset(data=data, char2index=char2index)\n",
    "test_text.__getitem__(110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HkGv6HZs9V5N"
   },
   "outputs": [],
   "source": [
    "\n",
    "code_dataset = TextDataset(data, char2index=char2index)\n",
    "# we can directly reuse the padding function which is implemented in last section.\n",
    "dataloader = DataLoader(code_dataset, batch_size=2,\n",
    "                        shuffle=True, num_workers=1,\n",
    "                        collate_fn=padding)\n",
    "for index, batch in enumerate(dataloader):\n",
    "    print(batch[\"input\"])\n",
    "    print(batch[\"output\"])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WYhthg-BiEKl"
   },
   "source": [
    "### Build the neural net architecture\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE37WmWlRck8"
   },
   "outputs": [],
   "source": [
    "def text_generation(model, start_seq, char2index, index2char, max_len=100):\n",
    "    model.eval()\n",
    "    input_seq = np.array([char2index[i] for i in start_seq])\n",
    "    input_seq = torch.from_numpy(input_seq).long().to(device)\n",
    "    input_seq = torch.unsqueeze(input_seq, 0)\n",
    "    output_seq = copy.deepcopy(input_seq)\n",
    "    batch_size = input_seq.shape[0]\n",
    "    hidden = [torch.zeros([num_layers * (int(bidirectional) + 1), batch_size, hidden_size]).to(device), \n",
    "              torch.zeros([num_layers * (int(bidirectional) + 1), batch_size, hidden_size]).to(device)]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        new_char_prob, hidden = model(input_seq, hidden)\n",
    "        new_char_prob = new_char_prob[:, -1]\n",
    "        new_char = torch.distributions.categorical.Categorical(logits=new_char_prob).sample() # output is a Long tensor\n",
    "        new_char = new_char.item() # transform to numpy \n",
    "        input_seq = torch.ones(1, 1).type_as(input_seq).fill_(new_char)\n",
    "        output_seq = torch.cat([output_seq, input_seq], dim=1)\n",
    "    \n",
    "    generate_text = \"\".join([index2char[i] for i in output_seq.cpu().numpy()[0]])\n",
    "\n",
    "    assert type(generate_text) is str\n",
    "    return generate_text\n",
    "\n",
    "def record_generate_text(tensorflow_writer, epoch, model, start_seq, char2index, index2char, max_len=100):\n",
    "    generate_text = text_generation(model, start_seq, char2index, index2char, max_len)\n",
    "    tensorflow_writer.add_text(\"{}th epoch\".format(epoch),\n",
    "                              \"\".join([i if i != \"/n\" else \"/n/n\" for i in generate_text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdXkhxShv1xU"
   },
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "hidden_size=512\n",
    "embedding_size=256\n",
    "bidirectional = False\n",
    "dropout=0.7\n",
    "epochs = 50\n",
    "test_freq = 1000\n",
    "batch_size=64\n",
    "\n",
    "model_code = CharRNN(input_size=len(char2index), \n",
    "                     embedding_size=embedding_size, \n",
    "                     lstm_hidden_size=hidden_size, \n",
    "                     lstm_num_layers=num_layers, \n",
    "                     lstm_bidirectional=bidirectional, \n",
    "                     lstm_dropout=dropout, \n",
    "                     last_dropout=0.5)\n",
    "\n",
    "critiria = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model_code.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9aawySWMPCZ"
   },
   "outputs": [],
   "source": [
    "# create a tensorboard writer instance. \n",
    "writer_code = SummaryWriter(flush_secs=10)\n",
    "\n",
    "# \n",
    "data, char2index, index2char = generate_data(filepath, segment_length=100)\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "validation = data[~msk]\n",
    "\n",
    "train_set      = TextDataset(train, char2index=char2index)\n",
    "validation_set = TextDataset(validation, char2index=char2index)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size,\n",
    "                          shuffle=True, num_workers=6, \n",
    "                          collate_fn=padding)\n",
    "\n",
    "validation_loader = DataLoader(validation_set, batch_size=batch_size,\n",
    "                               shuffle=True, num_workers=6, \n",
    "                               collate_fn=padding)\n",
    "    \n",
    "# if you want change to GPU mode, you just need to let device = \"cuda:0\" where 0 indicate the first gpu in your computer.\n",
    "device='cuda' \n",
    "model_code.to(device)\n",
    "operations_for_code = dnn_operations(model=model_code, loss_fn=critiria, optimizer=optimizer)\n",
    "for epoch in range(20):\n",
    "    train_loss = operations_for_code.train(dataloader=train_loader, device=device)\n",
    "    eval_loss = operations_for_code.eval(dataloader=validation_loader, device=device)\n",
    "    result_recording(writer_code, train_loss, eval_loss, epoch)\n",
    "    record_generate_text(writer_code, epoch, operations_for_code.model, \"#include\", char2index, index2char, max_len=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ABoUU25Hu2Z"
   },
   "outputs": [],
   "source": [
    "generate_text = text_generation(operations_for_code.model, \"#include\", char2index, index2char, max_len=10000)\n",
    "print(\"\".join([i if i != \"/n\" else \"/n/n\" for i in generate_text]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
